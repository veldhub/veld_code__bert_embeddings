{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "335dd6cf-f695-495a-ad89-54c79c271704",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae7ca8c-92e2-4492-bfe8-8bdf774252ca",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b851009-b15e-4d63-84c9-fed9e8d4b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from textwrap import dedent\n",
    "\n",
    "import numpy as np\n",
    "import psycopg\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pgvector.psycopg import register_vector\n",
    "from psycopg.sql import SQL, Identifier, Literal\n",
    "from sklearn.manifold import TSNE\n",
    "from spacy.tokens import Doc\n",
    "from transformers import AutoModel, AutoTokenizer, XLMRobertaModel, XLMRobertaTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14c2bd1-4a70-4143-9843-b87ed68ab820",
   "metadata": {},
   "source": [
    "## global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720552e3-a310-43d8-b93c-6d95a61ad360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "ENABLE_TEST = True\n",
    "TABLE_NAME_SENTENCES = os.getenv(\"table_name_sentences\")\n",
    "TABLE_NAME_LEMMAS = os.getenv(\"table_name_lemmas\")\n",
    "TABLE_NAME_EMBEDDINGS = os.getenv(\"table_name_embeddings\")\n",
    "INPUT_FILE_PATH = \"/veld/input/\" + os.getenv(\"input_file\")\n",
    "\n",
    "# models\n",
    "# MODEL_NAME = \"deepset/gbert-base\"\n",
    "MODEL_NAME = \"dbmdz/bert-base-german-cased\"\n",
    "# MODEL_NAME = \"FacebookAI/xlm-roberta-large\"\n",
    "# MODEL_NAME = \"FacebookAI/roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "# tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "# model = XLMRobertaModel.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n",
    "nlp = spacy.load(os.getenv(\"spacy_model\"))\n",
    "\n",
    "# DB\n",
    "conn = psycopg.connect(\n",
    "    dbname=os.getenv(\"POSTGRES_DB\"),\n",
    "    user=os.getenv(\"POSTGRES_USER\"),\n",
    "    password=os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "    host=os.getenv(\"POSTGRES_HOST\"),\n",
    ")\n",
    "conn.autocommit = True\n",
    "register_vector(conn)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT version();\")\n",
    "print(cursor.fetchone())\n",
    "\n",
    "\n",
    "# data structures\n",
    "@dataclass\n",
    "class SentenceEmbedded:\n",
    "    sent_id: int\n",
    "    text: str\n",
    "    token_list: list\n",
    "    embedding_list: list\n",
    "    lemma_list: list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55945077-52aa-4dc9-b343-2df99079b235",
   "metadata": {},
   "source": [
    "# modular functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d83b9-2e65-4389-9a6b-ac755dc86cb8",
   "metadata": {},
   "source": [
    "## set_up_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d1019-4378-4c1b-b009-10ec11d86b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_db():\n",
    "    for table_name in [TABLE_NAME_EMBEDDINGS, TABLE_NAME_LEMMAS, TABLE_NAME_SENTENCES]:\n",
    "        query = SQL(\"DROP TABLE IF EXISTS {table_name}\").format(table_name=Identifier(table_name))\n",
    "        print(query.as_string())\n",
    "        cursor.execute(query)\n",
    "\n",
    "    # sentences\n",
    "    query = SQL(\n",
    "        dedent(\n",
    "            \"\"\"\\\n",
    "            CREATE TABLE {table_name_sentences} (\n",
    "                sentence_id INTEGER PRIMARY KEY,\n",
    "                text TEXT\n",
    "            )\n",
    "            \"\"\"\n",
    "        )\n",
    "    ).format(table_name_sentences=Identifier(TABLE_NAME_SENTENCES))\n",
    "    print(query.as_string())\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # lemmas\n",
    "    query = SQL(\n",
    "        dedent(\n",
    "            \"\"\"\\\n",
    "            CREATE TABLE {table_name_lemmas} (\n",
    "                lemma_id SERIAL PRIMARY KEY,\n",
    "                lemma_text TEXT,\n",
    "                CONSTRAINT lemma_text_unique UNIQUE (lemma_text)\n",
    "            )\n",
    "            \"\"\"\n",
    "        )\n",
    "    ).format(table_name_lemmas=Identifier(TABLE_NAME_LEMMAS))\n",
    "    print(query.as_string())\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # embeddings\n",
    "    query = SQL(\n",
    "        dedent(\n",
    "            \"\"\"\\\n",
    "            CREATE TABLE {table_name_embeddings} (\n",
    "                token_text TEXT,\n",
    "                token_id INTEGER,\n",
    "                lemma_id_fk INTEGER REFERENCES {table_name_lemmas}(lemma_id),\n",
    "                sentence_id_fk INTEGER REFERENCES {table_name_sentences}(sentence_id),\n",
    "                PRIMARY KEY (sentence_id_fk, token_id),\n",
    "                embedding VECTOR({vector_dim})\n",
    "            )\n",
    "            \"\"\"\n",
    "        )\n",
    "    ).format(\n",
    "        table_name_embeddings=Identifier(TABLE_NAME_EMBEDDINGS),\n",
    "        table_name_lemmas=Identifier(TABLE_NAME_LEMMAS),\n",
    "        table_name_sentences=Identifier(TABLE_NAME_SENTENCES),\n",
    "        vector_dim=Literal(768),\n",
    "    )\n",
    "    print(query.as_string())\n",
    "    cursor.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e17a182-9b54-4bf4-b921-fb2b499fe026",
   "metadata": {},
   "source": [
    "## create_sent_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168fe47b-dafc-4225-8930-8a2ab664c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sent_embedded(sent_id, sent, tokens_list, embeddings_list):\n",
    "    token_list = []\n",
    "    embedding_list = []\n",
    "    lemma_list = []\n",
    "    t_prev = None\n",
    "    e_prev = []\n",
    "    for i, (t, e) in enumerate(zip(tokens_list, embeddings_list)):\n",
    "        if t and t.startswith(\"##\"):\n",
    "            t_prev += t[2:]\n",
    "            e_prev.append(e)\n",
    "        else:\n",
    "            if t_prev:\n",
    "                token_list.append(t_prev)\n",
    "                embedding_list.append(torch.mean(torch.stack(e_prev), dim=0))\n",
    "            t_prev = t\n",
    "            e_prev = [e]\n",
    "    token_list.append(t_prev)\n",
    "    embedding_list.append(torch.mean(torch.stack(e_prev), dim=0))\n",
    "\n",
    "    doc = Doc(nlp.vocab, words=token_list)\n",
    "    doc = nlp.get_pipe(\"tok2vec\")(doc)\n",
    "    doc = nlp.get_pipe(\"lemmatizer\")(doc)\n",
    "    for token in doc:\n",
    "        lemma_list.append(token.lemma_)\n",
    "\n",
    "    return SentenceEmbedded(\n",
    "        sent_id=sent_id,\n",
    "        text=sent,\n",
    "        token_list=token_list,\n",
    "        embedding_list=embedding_list,\n",
    "        lemma_list=lemma_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2f12f7-6510-455f-a8f6-4358325ec032",
   "metadata": {},
   "source": [
    "## infer_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21902b-271e-4ce0-99ca-2f7040ac5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_embeddings(sent_id, sent):\n",
    "    inputs = tokenizer(sent, return_tensors=\"pt\", add_special_tokens=True)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    return create_sent_embedded(sent_id, sent, tokens, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967058b5-6624-481a-a8b9-8a4511ad1d1c",
   "metadata": {},
   "source": [
    "## insert_into_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c6ab11-53ff-4667-848a-988bcdf45a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_into_db(table, sent_embedded):\n",
    "\n",
    "    query = SQL(\n",
    "        \"INSERT INTO {table_name_sentences} (sentence_id, text) VALUES (%s, %s)\"\n",
    "    ).format(table_name_sentences=Identifier(TABLE_NAME_SENTENCES))\n",
    "    if ENABLE_TEST:\n",
    "        print(query.as_string())\n",
    "    cursor.execute(query, (sent_embedded.sent_id, sent_embedded.text))\n",
    "\n",
    "    for token_id, (token_text, lemma_text, embedding) in enumerate(\n",
    "        zip(sent_embedded.token_list, sent_embedded.lemma_list, sent_embedded.embedding_list)\n",
    "    ):\n",
    "\n",
    "        # lemmas\n",
    "        query = SQL(\n",
    "            dedent(\n",
    "                \"\"\"\\\n",
    "                INSERT INTO {table_name_lemmas} (lemma_text) VALUES ({lemma_text})\n",
    "                ON CONFLICT (lemma_text) DO NOTHING\n",
    "                \"\"\"\n",
    "            )\n",
    "        ).format(\n",
    "            table_name_lemmas=Identifier(TABLE_NAME_LEMMAS),\n",
    "            lemma_text=Literal(lemma_text),\n",
    "        )\n",
    "        if ENABLE_TEST:\n",
    "            print(query.as_string())\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # embeddings\n",
    "        query = SQL(\n",
    "            dedent(\n",
    "                \"\"\"\\\n",
    "                INSERT INTO {table_name_embeddings} (\n",
    "                    token_text,\n",
    "                    token_id,\n",
    "                    lemma_id_fk,\n",
    "                    sentence_id_fk,\n",
    "                    embedding\n",
    "                )\n",
    "                VALUES (\n",
    "                    %s,\n",
    "                    {token_id},\n",
    "                    (SELECT lemma_id from {table_name_lemmas} WHERE lemma_text=%s),\n",
    "                    {sentence_id_fk},\n",
    "                    %s\n",
    "                )\n",
    "                \"\"\"\n",
    "            )\n",
    "        ).format(\n",
    "            table_name_embeddings=Identifier(TABLE_NAME_EMBEDDINGS),\n",
    "            table_name_lemmas=Identifier(TABLE_NAME_LEMMAS),\n",
    "            token_id=Literal(token_id),\n",
    "            sentence_id_fk=Literal(sent_embedded.sent_id)\n",
    "        )\n",
    "        if ENABLE_TEST:\n",
    "            print(query.as_string())\n",
    "        cursor.execute(query, (token_text, lemma_text, embedding.tolist(),))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5867d301-903a-4c27-9bb1-dfef7b4c1e67",
   "metadata": {},
   "source": [
    "## iterate_over_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33187e-4cc0-4899-9b7e-ae88d6052d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_over_file():\n",
    "    with open(INPUT_FILE_PATH, \"r\") as file:\n",
    "        for line in file:\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c5f433-aeab-48c1-8744-edca8504bf9b",
   "metadata": {},
   "source": [
    "# inference and persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a47d34-485d-48c8-9f04-75aa4872bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_up_db()\n",
    "\n",
    "limit = 10\n",
    "for sent_id, sent in enumerate(iterate_over_file()):\n",
    "    if ENABLE_TEST and sent_id == limit:\n",
    "        break\n",
    "    sent_embedded = infer_embeddings(sent_id, sent)\n",
    "    if ENABLE_TEST:\n",
    "        print(\"-------------------------------------------------------------\")\n",
    "        print(sent.replace(\"\\n\", \"\"))\n",
    "        print(sent_embedded.token_list)\n",
    "        print(sent_embedded.lemma_list)\n",
    "    insert_into_db(TABLE_NAME_EMBEDDINGS, sent_embedded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
