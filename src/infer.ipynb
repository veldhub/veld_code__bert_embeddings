{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b851009-b15e-4d63-84c9-fed9e8d4b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import psycopg\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import XLMRobertaModel, XLMRobertaTokenizer\n",
    "from pgvector.psycopg import register_vector\n",
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7554c3a2-0002-4c37-946f-fb5035250dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(\n",
    "    dbname=\"postgres_db\",\n",
    "    user=\"postgres_user\",\n",
    "    password=\"postgres_password\",\n",
    "    host=\"veld_embeddings_platform_run_server\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "conn.autocommit = True\n",
    "register_vector(conn)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT version();\")\n",
    "print(cursor.fetchone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720552e3-a310-43d8-b93c-6d95a61ad360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_NAME = \"deepset/gbert-base\"\n",
    "MODEL_NAME = \"dbmdz/bert-base-german-cased\"\n",
    "#MODEL_NAME = \"FacebookAI/xlm-roberta-large\"\n",
    "#MODEL_NAME = \"FacebookAI/roberta-large\"\n",
    "TABLE = \"embeddings__dbmdz__bert_base_german_cased__test\"\n",
    "IS_TEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068756b4-bf39-4f82-821a-2993c205c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "#tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "#model = XLMRobertaModel.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n",
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd44f068-665e-41fc-ab97-10b228fdb7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TextEmbedded:\n",
    "    text: str\n",
    "    token_list: list\n",
    "    embedding_list: list\n",
    "    lemma_list: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168fe47b-dafc-4225-8930-8a2ab664c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_embedded(text, tokens_list, embeddings_list):\n",
    "    \n",
    "    token_embedding_pair_list = []\n",
    "    token_list = []\n",
    "    embedding_list = []\n",
    "    lemma_list = []\n",
    "    t_prev = None\n",
    "    e_prev = []\n",
    "    for i, (t, e) in enumerate(zip(tokens_list, embeddings_list)):\n",
    "        if t and t.startswith(\"##\"):\n",
    "            t_prev += t[2:]\n",
    "            e_prev.append(e)\n",
    "        else:\n",
    "            if t_prev:\n",
    "                token_list.append(t_prev)\n",
    "                embedding_list.append(torch.mean(torch.stack(e_prev), dim=0))\n",
    "            t_prev = t\n",
    "            e_prev = [e]\n",
    "    token_list.append(t_prev)\n",
    "    embedding_list.append(torch.mean(torch.stack(e_prev), dim=0))\n",
    "\n",
    "    doc = Doc(nlp.vocab, words=token_list)\n",
    "    doc = nlp.get_pipe(\"tok2vec\")(doc)\n",
    "    doc = nlp.get_pipe(\"lemmatizer\")(doc)\n",
    "    for token in doc:\n",
    "        lemma_list.append(token.lemma_)\n",
    "    \n",
    "    return TextEmbedded(text=text, token_list=token_list, embedding_list=embedding_list, lemma_list=lemma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21902b-271e-4ce0-99ca-2f7040ac5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=True)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    return create_text_embedded(text, tokens, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c6ab11-53ff-4667-848a-988bcdf45a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_into_db(table, text_embedded):\n",
    "    cursor.execute(\n",
    "        f\"insert into sentences (text) values (%s) returning sentence_id\",\n",
    "        ((text_embedded.text, ))\n",
    "    )\n",
    "    sentence_id = cursor.fetchone()[0]\n",
    "    for token_index, (token, lemma, embedding) in enumerate(zip(text_embedded.token_list, text_embedded.lemma_list, text_embedded.embedding_list)):\n",
    "        cursor.execute(\n",
    "            \"insert into lemma (lemma) values (%s) on conflict (lemma) do nothing\",\n",
    "            ((lemma,))\n",
    "        )\n",
    "        cursor.execute(\n",
    "            f\"insert into {table} (sentence_id, token_index, word, lemma, embedding) values (%s, %s, %s, %s, %s)\",\n",
    "            (sentence_id, token_index, token, lemma, embedding.tolist())\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33187e-4cc0-4899-9b7e-ae88d6052d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_over_file():\n",
    "    with open(\"/veld/input/data.txt\", \"r\") as f:\n",
    "        for l in f:\n",
    "            yield l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a47d34-485d-48c8-9f04-75aa4872bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 20\n",
    "for i, text in enumerate(iterate_over_file()):\n",
    "    if IS_TEST and i == limit - 1:\n",
    "        break\n",
    "    text_embedded = get_embeddings(text)\n",
    "    print(text_embedded.lemma_list)\n",
    "    print(text_embedded.token_list)\n",
    "    print(text)\n",
    "    insert_into_db(TABLE, text_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2e62f0-1892-4f60-9125-20f0a5e04a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
