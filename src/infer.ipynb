{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b851009-b15e-4d63-84c9-fed9e8d4b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import psycopg\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import XLMRobertaModel, XLMRobertaTokenizer\n",
    "from pgvector.psycopg import register_vector\n",
    "from sklearn.manifold import TSNE\n",
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7554c3a2-0002-4c37-946f-fb5035250dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(\n",
    "    dbname=\"postgres_db\",\n",
    "    user=\"postgres_user\",\n",
    "    password=\"postgres_password\",\n",
    "    host=\"veld_embeddings_platform_run_sql_server\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "conn.autocommit = True\n",
    "register_vector(conn)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT version();\")\n",
    "print(cursor.fetchone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720552e3-a310-43d8-b93c-6d95a61ad360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_NAME = \"deepset/gbert-base\"\n",
    "MODEL_NAME = \"dbmdz/bert-base-german-cased\"\n",
    "#MODEL_NAME = \"FacebookAI/xlm-roberta-large\"\n",
    "#MODEL_NAME = \"FacebookAI/roberta-large\"\n",
    "TABLE = \"embeddings__dbmdz__bert_base_german_cased__test\"\n",
    "IS_TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068756b4-bf39-4f82-821a-2993c205c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "#tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "#model = XLMRobertaModel.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n",
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd44f068-665e-41fc-ab97-10b228fdb7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TextEmbedded:\n",
    "    text: str\n",
    "    token_list: list\n",
    "    embedding_list: list\n",
    "    lemma_list: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168fe47b-dafc-4225-8930-8a2ab664c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_embedded(text, tokens_list, embeddings_list):\n",
    "    \n",
    "    token_embedding_pair_list = []\n",
    "    token_list = []\n",
    "    embedding_list = []\n",
    "    lemma_list = []\n",
    "    t_prev = None\n",
    "    e_prev = []\n",
    "    for i, (t, e) in enumerate(zip(tokens_list, embeddings_list)):\n",
    "        if t and t.startswith(\"##\"):\n",
    "            t_prev += t[2:]\n",
    "            e_prev.append(e)\n",
    "        else:\n",
    "            if t_prev:\n",
    "                token_list.append(t_prev)\n",
    "                embedding_list.append(torch.mean(torch.stack(e_prev), dim=0))\n",
    "            t_prev = t\n",
    "            e_prev = [e]\n",
    "    token_list.append(t_prev)\n",
    "    embedding_list.append(torch.mean(torch.stack(e_prev), dim=0))\n",
    "\n",
    "    doc = Doc(nlp.vocab, words=token_list)\n",
    "    doc = nlp.get_pipe(\"tok2vec\")(doc)\n",
    "    doc = nlp.get_pipe(\"lemmatizer\")(doc)\n",
    "    for token in doc:\n",
    "        lemma_list.append(token.lemma_)\n",
    "    \n",
    "    return TextEmbedded(text=text, token_list=token_list, embedding_list=embedding_list, lemma_list=lemma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21902b-271e-4ce0-99ca-2f7040ac5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=True)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    return create_text_embedded(text, tokens, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c6ab11-53ff-4667-848a-988bcdf45a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_into_db(table, text_embedded):\n",
    "    cursor.execute(\n",
    "        f\"insert into sentences (text) values (%s) returning sentence_id\",\n",
    "        ((text_embedded.text, ))\n",
    "    )\n",
    "    sentence_id = cursor.fetchone()[0]\n",
    "    for token_index, (token, lemma, embedding) in enumerate(zip(text_embedded.token_list, text_embedded.lemma_list, text_embedded.embedding_list)):\n",
    "        cursor.execute(\n",
    "            \"insert into lemma (lemma) values (%s) on conflict (lemma) do nothing\",\n",
    "            ((lemma,))\n",
    "        )\n",
    "        cursor.execute(\n",
    "            f\"insert into {table} (sentence_id, token_index, word, lemma, embedding) values (%s, %s, %s, %s, %s)\",\n",
    "            (sentence_id, token_index, token, lemma, embedding.tolist())\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33187e-4cc0-4899-9b7e-ae88d6052d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_over_file():\n",
    "    with open(\"/veld/input/data.txt\", \"r\") as f:\n",
    "        for l in f:\n",
    "            yield l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a47d34-485d-48c8-9f04-75aa4872bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 20\n",
    "for i, text in enumerate(iterate_over_file()):\n",
    "    if IS_TEST and i == limit - 1:\n",
    "        break\n",
    "    text_embedded = get_embeddings(text)\n",
    "    #print(text_embedded.lemma_list)\n",
    "    #print(text_embedded.token_list)\n",
    "    #print(text)\n",
    "    insert_into_db(TABLE, text_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174029a3-3731-4732-a87a-53cdc465372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot_tsne(rows, title=None):\n",
    "\n",
    "    # get labels and values\n",
    "    #labels = []\n",
    "    #values = []\n",
    "    #for w in WORD_LIST:\n",
    "    #    labels.append(w)\n",
    "    #    values.append(vector_dict[w])\n",
    "    labels = [r[0] for r in rows]\n",
    "    values = [r[1] for r in rows]\n",
    "    values = np.array(values)\n",
    "\n",
    "    # reduce\n",
    "    tsne = TSNE(n_components=2, perplexity=5, random_state=42)\n",
    "    reduced_vectors_tsne = tsne.fit_transform(values)\n",
    "    \n",
    "    # Plot the reduced vectors\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(reduced_vectors_tsne[:, 0], reduced_vectors_tsne[:, 1], c='blue', alpha=0.7)\n",
    "\n",
    "    # Add labels\n",
    "    for i, label in enumerate(labels):\n",
    "        plt.text(\n",
    "            reduced_vectors_tsne[i, 0], \n",
    "            reduced_vectors_tsne[i, 1], \n",
    "            label,\n",
    "            fontsize=9, \n",
    "            ha=\"right\", \n",
    "            color=\"black\"\n",
    "        )\n",
    "        \n",
    "    # plot\n",
    "    #plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb3caea-8ca9-4b59-872c-695a63e4bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\n",
    "    \"select lemma, embedding \"\n",
    "    \"from embeddings__dbmdz__bert_base_german_cased__test \"\n",
    "    \"where lemma='Frau';\"\n",
    ")\n",
    "rows_frau = cursor.fetchall()\n",
    "\n",
    "cursor.execute(\n",
    "    \"select lemma, embedding \"\n",
    "    \"from embeddings__dbmdz__bert_base_german_cased__test \"\n",
    "    \"where lemma='Mann';\"\n",
    ")\n",
    "rows_mann = cursor.fetchall()\n",
    "\n",
    "rows_together = rows_frau + rows_mann\n",
    "show_plot_tsne(rows_together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c1301-f597-4019-aa5f-362f7bab1bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_col_to_label(rows):\n",
    "    rows_new = []\n",
    "    for r in rows:\n",
    "        if False:\n",
    "            rows_new.append((r[0] + \"-\" + str(r[1]) + \"-\" + str(r[2]), r[3]))\n",
    "        else:\n",
    "            rows_new.append((r[0], r[3]))\n",
    "    return rows_new\n",
    "\n",
    "cursor.execute(\n",
    "    \"select lemma, sentence_id, token_index, embedding \"\n",
    "    \"from embeddings__dbmdz__bert_base_german_cased__test \"\n",
    "    \"where lemma='Frau'order by sentence_id limit 50;\"\n",
    ")\n",
    "rows_frau = cursor.fetchall()\n",
    "\n",
    "cursor.execute(\n",
    "    \"select lemma, sentence_id, token_index, embedding \"\n",
    "    \"from embeddings__dbmdz__bert_base_german_cased__test \"\n",
    "    \"where lemma='Mann' order by sentence_id limit 50;\"\n",
    ")\n",
    "rows_mann = cursor.fetchall()\n",
    "\n",
    "rows_together = rows_frau + rows_mann\n",
    "rows_together = merge_col_to_label(rows_together)\n",
    "show_plot_tsne(rows_together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc802ade-67d5-4454-9a39-f272aa578de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_col_to_label(rows):\n",
    "    rows_new = []\n",
    "    for r in rows:\n",
    "        if True:\n",
    "            rows_new.append((r[0] + \"-\" + str(r[1]) + \"-\" + str(r[2]), r[3]))\n",
    "        else:\n",
    "            rows_new.append((r[0], r[3]))\n",
    "    return rows_new\n",
    "\n",
    "cursor.execute(\n",
    "    \"select lemma, sentence_id, token_index, embedding \"\n",
    "    \"from embeddings__dbmdz__bert_base_german_cased__test \"\n",
    "    \"where lemma='Frau'order by sentence_id limit 50;\"\n",
    ")\n",
    "rows_frau = cursor.fetchall()\n",
    "\n",
    "cursor.execute(\n",
    "    \"select lemma, sentence_id, token_index, embedding \"\n",
    "    \"from embeddings__dbmdz__bert_base_german_cased__test \"\n",
    "    \"where lemma='Mann' order by sentence_id limit 50;\"\n",
    ")\n",
    "rows_mann = cursor.fetchall()\n",
    "\n",
    "rows_together = rows_frau + rows_mann\n",
    "rows_together = merge_col_to_label(rows_together)\n",
    "show_plot_tsne(rows_together)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
