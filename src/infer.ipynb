{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b851009-b15e-4d63-84c9-fed9e8d4b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import XLMRobertaModel, XLMRobertaTokenizer\n",
    "import torch.nn.functional as F\n",
    "import psycopg\n",
    "from pgvector.psycopg import register_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7554c3a2-0002-4c37-946f-fb5035250dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PostgreSQL 17.4 on x86_64-pc-linux-gnu, compiled by gcc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit',)\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg.connect(\n",
    "    dbname=\"postgres_db\",\n",
    "    user=\"postgres_user\",\n",
    "    password=\"postgres_password\",\n",
    "    host=\"veld_embeddings_platform_run_server\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "register_vector(conn)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT version();\")\n",
    "print(cursor.fetchone())\n",
    "#cursor.close()\n",
    "#conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "720552e3-a310-43d8-b93c-6d95a61ad360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_NAME = \"deepset/gbert-base\"\n",
    "MODEL_NAME = \"dbmdz/bert-base-german-cased\"\n",
    "#MODEL_NAME = \"FacebookAI/xlm-roberta-large\"\n",
    "#MODEL_NAME = \"FacebookAI/roberta-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "068756b4-bf39-4f82-821a-2993c205c97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(31102, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "#tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "#model = XLMRobertaModel.from_pretrained(MODEL_NAME)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d21902b-271e-4ce0-99ca-2f7040ac5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=True)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    return embeddings, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e2889208-0f2f-4a7a-a53f-dc7578d907a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_1, tokens_1 = get_vectors(\"Ich sitze auf der Bank.\")\n",
    "embeddings_2, tokens_2 = get_vectors(\"Diese Bank ist aus Holz.\")\n",
    "embeddings_3, tokens_3 = get_vectors(\"Susi arbeitet in einer internationalen Bank.\")\n",
    "embeddings_4, tokens_4 = get_vectors(\"Ich lege mein Geld bei dieser Bank in Wertpapiere an.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f82e242c-4804-4153-b938-5217fc8a103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 768])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([10, 768])\n",
      "torch.Size([15, 768])\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_1.shape)\n",
    "print(embeddings_2.shape)\n",
    "print(embeddings_3.shape)\n",
    "print(embeddings_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "291485e1-d6ea-4841-bf08-299cf2090293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "8\n",
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens_1))\n",
    "print(len(tokens_2))\n",
    "print(len(tokens_3))\n",
    "print(len(tokens_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fa9b0c8-3314-4c8f-aab6-2cad9b8ab805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Ich', 'sit', '##ze', 'auf', 'der', 'Bank', '.', '[SEP]']\n",
      "Bank\n",
      "['[CLS]', 'Diese', 'Bank', 'ist', 'aus', 'Holz', '.', '[SEP]']\n",
      "Bank\n",
      "['[CLS]', 'Sus', '##i', 'arbeitet', 'in', 'einer', 'internationalen', 'Bank', '.', '[SEP]']\n",
      "Bank\n",
      "['[CLS]', 'Ich', 'leg', '##e', 'mein', 'Geld', 'bei', 'dieser', 'Bank', 'in', 'Wertpapier', '##e', 'an', '.', '[SEP]']\n",
      "Bank\n"
     ]
    }
   ],
   "source": [
    "print(tokens_1)\n",
    "print(tokens_1[6])\n",
    "print(tokens_2)\n",
    "print(tokens_2[2])\n",
    "print(tokens_3)\n",
    "print(tokens_3[7])\n",
    "print(tokens_4)\n",
    "print(tokens_4[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51e811e4-1495-4a5d-9ded-5d1850bd7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_1 = embeddings_1[6]\n",
    "v_2 = embeddings_2[2]\n",
    "v_3 = embeddings_3[7]\n",
    "v_4 = embeddings_4[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d20937b0-913a-40ca-ab6f-e00eeaab199b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2 0.8286746740341187\n",
      "1, 3 0.8310555219650269\n",
      "1, 4 0.8268762230873108\n",
      "2, 3 0.7706555128097534\n",
      "2, 4 0.7725297212600708\n",
      "3, 4 0.8637327551841736\n"
     ]
    }
   ],
   "source": [
    "print(\"1, 2\", F.cosine_similarity(v_1, v_2, dim=0).item())\n",
    "print(\"1, 3\", F.cosine_similarity(v_1, v_3, dim=0).item())\n",
    "print(\"1, 4\", F.cosine_similarity(v_1, v_4, dim=0).item())\n",
    "print(\"2, 3\", F.cosine_similarity(v_2, v_3, dim=0).item())\n",
    "print(\"2, 4\", F.cosine_similarity(v_2, v_4, dim=0).item())\n",
    "print(\"3, 4\", F.cosine_similarity(v_3, v_4, dim=0).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06338cc6-2028-4278-93e6-046e0799d5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2334f908-2621-48d8-895f-d46ba5bf1b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 768])\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_1.shape)\n",
    "print(len(tokens_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e05db5f4-d8d6-41b5-a05c-86a68f5b9853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_sub_tokens(tokens_list, embeddings_list):\n",
    "    tokens_list_new = []\n",
    "    embeddings_list_new = []\n",
    "    t_prev = None\n",
    "    e_prev = []\n",
    "    for i, (t, e) in enumerate(zip(tokens_list, embeddings_list)):\n",
    "        if t and t.startswith(\"##\"):\n",
    "            t_prev += t[2:]\n",
    "            e_prev.append(e)\n",
    "        else:\n",
    "            if t_prev:\n",
    "                tokens_list_new.append(t_prev)\n",
    "                embeddings_list_new.append(torch.mean(torch.stack(e_prev), dim=0))\n",
    "            t_prev = t\n",
    "            e_prev = [e]\n",
    "    tokens_list_new.append(t_prev)\n",
    "    embeddings_list_new.append(torch.mean(torch.stack(e_prev), dim=0))\n",
    "    embeddings_list_new = torch.stack(embeddings_list_new)\n",
    "    return tokens_list_new, embeddings_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0f6074d6-9eb0-4ed3-b905-2aac5bea2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_4_new, embeddings_4_new = aggregate_sub_tokens(tokens_4, embeddings_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "74149781-773c-414a-971a-bffba68946d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'Ich',\n",
       " 'leg',\n",
       " '##e',\n",
       " 'mein',\n",
       " 'Geld',\n",
       " 'bei',\n",
       " 'dieser',\n",
       " 'Bank',\n",
       " 'in',\n",
       " 'Wertpapier',\n",
       " '##e',\n",
       " 'an',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0d060ef0-ac66-4291-88c2-e3b8148c6686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'Ich',\n",
       " 'lege',\n",
       " 'mein',\n",
       " 'Geld',\n",
       " 'bei',\n",
       " 'dieser',\n",
       " 'Bank',\n",
       " 'in',\n",
       " 'Wertpapiere',\n",
       " 'an',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_4_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "39a104d5-a377-4f64-9ecb-0157815d86e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 768])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3e6785ba-fa52-489c-a480-01f1c451dc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 768])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_4_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "87270c80-bba0-453f-b958-6b7d63dc072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_into_db(tokens, embeddings):\n",
    "    for t, e in zip(tokens, embeddings):\n",
    "        cursor.execute(\n",
    "            \"insert into dbmdz__bert_base_german_cased__test (word, embedding) values (%s, %s)\",\n",
    "            (t, e.tolist())\n",
    "        )\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "44f55f63-8e8f-4352-b576-1907f72d3d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_into_db(tokens_4_new, embeddings_4_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e679bec6-b7cb-44fe-9b48-840985fed5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
